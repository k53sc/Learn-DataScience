{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Introduction\n",
    "\n",
    "In the last mission, we began investigating possible relationships between SAT scores and demographic factors. In order to do this, we acquired several data sets about New York City public schools. We manipulated these data sets, and found that we could combine them all using the DBN column. All of the data sets are currently stored as keys in the data dictionary. Each individual data set is a pandas dataframe.\n",
    "\n",
    "In this mission, we'll clean the data a bit more, then combine it. Finally, we'll compute correlations and perform some analysis.\n",
    "\n",
    "The first thing we'll need to do in preparation for the merge is condense some of the data sets. In the last mission, we noticed that the values in the DBN column were unique in the sat_results data set. Other data sets like class_size had duplicate DBN values, however.\n",
    "\n",
    "We'll need to condense these data sets so that each value in the DBN column is unique. If not, we'll run into issues when it comes time to combine the data sets.\n",
    "\n",
    "While the main data set we want to analyze, sat_results, has unique DBN values for every high school in New York City, other data sets aren't as clean. A single row in the sat_results data set may match multiple columns in the class_size data set, for example. This situation will create problems, because we don't know which of the multiple entries in the class_size data set we should combine with the single matching entry in sat_results. Here's a diagram that illustrates the problem:\n",
    "\n",
    "<img src='cartesian_product.png'>\n",
    "\n",
    "In the diagram above, we can't just combine the rows from both data sets because there are several cases where multiple rows in class_size match a single row in sat_results.\n",
    "\n",
    "To resolve this issue, we'll condense the class_size, graduation, and demographics data sets so that each DBN is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2: Condensing the Class Size Data Set\n",
    "\n",
    "The first data set that we'll condense is class_size. The first few rows of class_size look like this:\n",
    "\t\n",
    "       CSD \tBOROUGH \tSCHOOL CODE \tSCHOOL NAME \tGRADE \tPROGRAM TYPE \tCORE SUBJECT (MS CORE and 9-12 ONLY) \tCORE COURSE (MS CORE and 9-12 ONLY) \tSERVICE CATEGORY(K-9* ONLY) \tNUMBER OF STUDENTS / SEATS FILLED \tNUMBER OF SECTIONS \tAVERAGE CLASS SIZE \tSIZE OF SMALLEST CLASS \tSIZE OF LARGEST CLASS \tDATA SOURCE \tSCHOOLWIDE PUPIL-TEACHER RATIO \tpadded_csd \tDBN\n",
    "    0 \t1 \tM \tM015 \tP.S. 015 Roberto Clemente \t0K \tGEN ED \t- \t- \t- \t19.0 \t1.0 \t19.0 \t19.0 \t19.0 \tATS \tNaN \t01 \t01M015\n",
    "    1 \t1 \tM \tM015 \tP.S. 015 Roberto Clemente \t0K \tCTT \t- \t- \t- \t21.0 \t1.0 \t21.0 \t21.0 \t21.0 \tATS \tNaN \t01 \t01M015\n",
    "    2 \t1 \tM \tM015 \tP.S. 015 Roberto Clemente \t01 \tGEN ED \t- \t- \t- \t17.0 \t1.0 \t17.0 \t17.0 \t17.0 \tATS \tNaN \t01 \t01M015\n",
    "    3 \t1 \tM \tM015 \tP.S. 015 Roberto Clemente \t01 \tCTT \t- \t- \t- \t17.0 \t1.0 \t17.0 \t17.0 \t17.0 \tATS \tNaN \t01 \t01M015\n",
    "    4 \t1 \tM \tM015 \tP.S. 015 Roberto Clemente \t02 \tGEN ED \t- \t- \t- \t15.0 \t1.0 \t15.0 \t15.0 \t15.0 \tATS \tNaN \t01 \t01M015\n",
    "\n",
    "As you can see, the first few rows all pertain to the same school, which is why the DBN appears more than once. It looks like each school has multiple values for GRADE, PROGRAM TYPE, CORE SUBJECT (MS CORE and 9-12 ONLY), and CORE COURSE (MS CORE and 9-12 ONLY).\n",
    "\n",
    "If we look at the unique values for GRADE, we get the following:\n",
    "\n",
    "    array(['0K', '01', '02', '03', '04', '05', '0K-09', nan, '06', '07', '08',\n",
    "\n",
    "       'MS Core', '09-12', '09'], dtype=object)\n",
    "\n",
    "Because we're dealing with high schools, we're only concerned with grades 9 through 12. That means we only want to pick rows where the value in the GRADE column is 09-12.\n",
    "\n",
    "If we look at the unique values for PROGRAM TYPE, we get the following:\n",
    "\n",
    "    array(['GEN ED', 'CTT', 'SPEC ED', nan, 'G&T'], dtype=object)\n",
    "\n",
    "Each school can have multiple program types. Because GEN ED is the largest category by far, let's only select rows where PROGRAM TYPE is GEN ED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Condensing the Class Size Data Set\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Create a new variable called class_size, and assign the value of data[\"class_size\"] to it.\n",
    "    Filter class_size so the GRADE column only contains the value 09-12. Note that the name of the GRADE column has a space at the end; you'll generate an error if you don't include it.\n",
    "    Filter class_size so that the PROGRAM TYPE column only contains the value GEN ED.\n",
    "    Display the first five rows of class_size to verify.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "data = {}\n",
    "\n",
    "for file in data_files:\n",
    "    df = pd.read_csv( \"../data/\" + file )\n",
    "    data[file.split( \".\" )[0]] = df\n",
    "    \n",
    "# normal string concatanation won't work here\n",
    "def pad_csd(num):\n",
    "    string_representation = str(num)\n",
    "    if len(string_representation) > 1:\n",
    "        return string_representation\n",
    "    else:\n",
    "        return string_representation.zfill(2)\n",
    "    \n",
    "\n",
    "data['hs_directory']['DBN'] = data['hs_directory']['dbn']\n",
    "\n",
    "data['class_size'][\"padded_csd\"] = data['class_size']['CSD'].apply( pad_csd )\n",
    "data['class_size'][\"DBN\"] = data['class_size'][\"padded_csd\"] + data['class_size'][\"SCHOOL CODE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CSD BOROUGH SCHOOL CODE                                    SCHOOL NAME  \\\n",
      "225    1       M        M292  Henry Street School for International Studies   \n",
      "226    1       M        M292  Henry Street School for International Studies   \n",
      "227    1       M        M292  Henry Street School for International Studies   \n",
      "228    1       M        M292  Henry Street School for International Studies   \n",
      "229    1       M        M292  Henry Street School for International Studies   \n",
      "\n",
      "    GRADE  PROGRAM TYPE CORE SUBJECT (MS CORE and 9-12 ONLY)  \\\n",
      "225  09-12       GEN ED                              ENGLISH   \n",
      "226  09-12       GEN ED                              ENGLISH   \n",
      "227  09-12       GEN ED                              ENGLISH   \n",
      "228  09-12       GEN ED                              ENGLISH   \n",
      "229  09-12       GEN ED                                 MATH   \n",
      "\n",
      "    CORE COURSE (MS CORE and 9-12 ONLY) SERVICE CATEGORY(K-9* ONLY)  \\\n",
      "225                           English 9                           -   \n",
      "226                          English 10                           -   \n",
      "227                          English 11                           -   \n",
      "228                          English 12                           -   \n",
      "229                  Integrated Algebra                           -   \n",
      "\n",
      "     NUMBER OF STUDENTS / SEATS FILLED  NUMBER OF SECTIONS  \\\n",
      "225                               63.0                 3.0   \n",
      "226                               79.0                 3.0   \n",
      "227                               38.0                 2.0   \n",
      "228                               69.0                 3.0   \n",
      "229                               53.0                 3.0   \n",
      "\n",
      "     AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  SIZE OF LARGEST CLASS  \\\n",
      "225                21.0                    19.0                   25.0   \n",
      "226                26.3                    24.0                   31.0   \n",
      "227                19.0                    16.0                   22.0   \n",
      "228                23.0                    13.0                   30.0   \n",
      "229                17.7                    16.0                   21.0   \n",
      "\n",
      "    DATA SOURCE  SCHOOLWIDE PUPIL-TEACHER RATIO padded_csd     DBN  \n",
      "225       STARS                             NaN         01  01M292  \n",
      "226       STARS                             NaN         01  01M292  \n",
      "227       STARS                             NaN         01  01M292  \n",
      "228       STARS                             NaN         01  01M292  \n",
      "229       STARS                             NaN         01  01M292  \n"
     ]
    }
   ],
   "source": [
    "class_size = data['class_size']\n",
    "class_size = class_size[ class_size['GRADE '] == '09-12']\n",
    "class_size = class_size[ class_size['PROGRAM TYPE'] == 'GEN ED']\n",
    "print( class_size.head( 5 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Computing Average Class Sizes\n",
    "\n",
    "As we saw when we displayed class_size on the last screen, DBN still isn't completely unique. This is due to the CORE COURSE (MS CORE and 9-12 ONLY) and CORE SUBJECT (MS CORE and 9-12 ONLY) columns.\n",
    "\n",
    "CORE COURSE (MS CORE and 9-12 ONLY) and CORE SUBJECT (MS CORE and 9-12 ONLY) seem to pertain to different kinds of classes. For example, here are the unique values for CORE SUBJECT (MS CORE and 9-12 ONLY):\n",
    "\n",
    "    array(['ENGLISH', 'MATH', 'SCIENCE', 'SOCIAL STUDIES'], dtype=object)\n",
    "\n",
    "This column only seems to include certain subjects. We want our class size data to include every single class a school offers -- not just a subset of them. What we can do is take the average across all of the classes a school offers. This will give us unique DBN values, while also incorporating as much data as possible into the average.\n",
    "\n",
    "Fortunately, we can use the pandas.DataFrame.groupby() method to help us with this. The DataFrame.groupby() method will split a dataframe up into unique groups, based on a given column. We can then use the agg() method on the resulting pandas.core.groupby object to find the mean of each column.\n",
    "\n",
    "Let's say we have this data set:\n",
    "\n",
    "<img src='classize_table.png'>\n",
    "\n",
    "Using the groupby() method, we'll split this dataframe into four separate groups -- one with the DBN 01M292, one with the DBN 01M332, one with the DBN 01M378, and one with the DBN 01M448:\n",
    "\n",
    "<img src='classsize_agg.png'>\n",
    "\n",
    "Then, we can compute the averages for the AVERAGE CLASS SIZE column in each of the four groups using the agg() method:\n",
    "\n",
    "<img src='classsize_result.png'>\n",
    "\n",
    "After we group a dataframe and aggregate data based on it, the column we performed the grouping on (in this case DBN) will become the index, and will no longer appear as a column in the data itself. To undo this change and keep DBN as a column, we'll need to use pandas.DataFrame.reset_index(). This method will reset the index to a list of integers and make DBN a column again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Computing Average Class Sizes\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Find the average values for each column associated with each DBN in class_size.\n",
    "        Use the pandas.DataFrame.groupby() method to group class_size by DBN.\n",
    "        Use the agg() method on the resulting pandas.core.groupby object, along with the numpy.mean() function as an argument, to calculate the average of each group.\n",
    "        Assign the result back to class_size.\n",
    "    Reset the index to make DBN a column again.\n",
    "        Use the pandas.DataFrame.reset_index() method, along with the keyword argument inplace=True.\n",
    "    Assign class_size back to the class_size key of the data dictionary.\n",
    "    Display the first few rows of data[\"class_size\"] to verify that everything went ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN  CSD  NUMBER OF STUDENTS / SEATS FILLED  NUMBER OF SECTIONS  \\\n",
      "0  01M292    1                            88.0000            4.000000   \n",
      "1  01M332    1                            46.0000            2.000000   \n",
      "2  01M378    1                            33.0000            1.000000   \n",
      "3  01M448    1                           105.6875            4.750000   \n",
      "4  01M450    1                            57.6000            2.733333   \n",
      "\n",
      "   AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  SIZE OF LARGEST CLASS  \\\n",
      "0           22.564286                   18.50              26.571429   \n",
      "1           22.000000                   21.00              23.500000   \n",
      "2           33.000000                   33.00              33.000000   \n",
      "3           22.231250                   18.25              27.062500   \n",
      "4           21.200000                   19.40              22.866667   \n",
      "\n",
      "   SCHOOLWIDE PUPIL-TEACHER RATIO  \n",
      "0                             NaN  \n",
      "1                             NaN  \n",
      "2                             NaN  \n",
      "3                             NaN  \n",
      "4                             NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "# this kind of approach does aggregation on each and every column\n",
    "class_size = class_size.groupby(\"DBN\").agg(numpy.mean)\n",
    "\n",
    "# After we group a dataframe and aggregate data based on it, \n",
    "# the column we performed the grouping on (in this case DBN) will become the index,\n",
    "# and will no longer appear as a column in the data itself. To undo this change and keep DBN as a column, \n",
    "# we'll need to use pandas.DataFrame.reset_index(). This method will reset the index to a list of integers and make DBN a column again.\n",
    "class_size.reset_index(inplace=True)\n",
    "data[\"class_size\"] = class_size\n",
    "print( data[\"class_size\"].head( 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 6: Condensing the Demographics Data Set\n",
    "\n",
    "Now that we've finished condensing class_size, let's condense demographics. The first few rows look like the cell above.\n",
    "\n",
    "In this case, the only column that prevents a given DBN from being unique is schoolyear. We only want to select rows where schoolyear is 20112012. This will give us the most recent year of data, and also match our SAT results data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 7: Condensing the Demographics Data Set\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Filter demographics, only selecting rows in data[\"demographics\"] where schoolyear is 20112012.\n",
    "        schoolyear is actually an integer, so be careful about how you perform your comparison.\n",
    "    Display the first few rows of data[\"demographics\"] to verify that the filtering worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DBN                                              Name  schoolyear  \\\n",
      "6   01M015  P.S. 015 ROBERTO CLEMENTE                           20112012   \n",
      "13  01M019  P.S. 019 ASHER LEVY                                 20112012   \n",
      "20  01M020  PS 020 ANNA SILVER                                  20112012   \n",
      "27  01M034  PS 034 FRANKLIN D ROOSEVELT                         20112012   \n",
      "35  01M063  PS 063 WILLIAM MCKINLEY                             20112012   \n",
      "\n",
      "   fl_percent  frl_percent  total_enrollment prek    k grade1 grade2  \\\n",
      "6         NaN         89.4               189   13   31     35     28   \n",
      "13        NaN         61.5               328   32   46     52     54   \n",
      "20        NaN         92.5               626   52  102    121     87   \n",
      "27        NaN         99.7               401   14   34     38     36   \n",
      "35        NaN         78.9               176   18   20     30     21   \n",
      "\n",
      "      ...     black_num black_per hispanic_num hispanic_per white_num  \\\n",
      "6     ...            63      33.3          109         57.7         4   \n",
      "13    ...            81      24.7          158         48.2        28   \n",
      "20    ...            55       8.8          357         57.0        16   \n",
      "27    ...            90      22.4          275         68.6         8   \n",
      "35    ...            41      23.3          110         62.5        15   \n",
      "\n",
      "   white_per male_num male_per female_num female_per  \n",
      "6        2.1     97.0     51.3       92.0       48.7  \n",
      "13       8.5    147.0     44.8      181.0       55.2  \n",
      "20       2.6    330.0     52.7      296.0       47.3  \n",
      "27       2.0    204.0     50.9      197.0       49.1  \n",
      "35       8.5     97.0     55.1       79.0       44.9  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "demographics = data['demographics']\n",
    "\n",
    "demographics = demographics[ demographics['schoolyear'] == 20112012 ]\n",
    "data['demographics'] = demographics\n",
    "print ( data['demographics'].head( 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8: Condensing the Graduation Data Set\n",
    "\n",
    "Finally, we'll need to condense the graduation data set. Here are the first few rows:\n",
    "\t\n",
    "    Demographic \tDBN \tSchool Name \tCohort \tTotal Cohort \tTotal Grads - n \tTotal Grads - % of cohort \tTotal Regents - n \tTotal Regents - % of cohort \tTotal Regents - % of grads \t... \tRegents w/o Advanced - n \tRegents w/o Advanced - % of cohort \tRegents w/o Advanced - % of grads \tLocal - n \tLocal - % of cohort \tLocal - % of grads \tStill Enrolled - n \tStill Enrolled - % of cohort \tDropped Out - n \tDropped Out - % of cohort\n",
    "    0 \tTotal Cohort \t01M292 \tHENRY STREET SCHOOL FOR INTERNATIONAL \t2003 \t5 \ts \ts \ts \ts \ts \t... \ts \ts \ts \ts \ts \ts \ts \ts \ts \ts\n",
    "    1 \tTotal Cohort \t01M292 \tHENRY STREET SCHOOL FOR INTERNATIONAL \t2004 \t55 \t37 \t67.3% \t17 \t30.9% \t45.9% \t... \t17 \t30.9% \t45.9% \t20 \t36.4% \t54.1% \t15 \t27.3% \t3 \t5.5%\n",
    "    2 \tTotal Cohort \t01M292 \tHENRY STREET SCHOOL FOR INTERNATIONAL \t2005 \t64 \t43 \t67.2% \t27 \t42.2% \t62.8% \t... \t27 \t42.2% \t62.8% \t16 \t25% \t37.200000000000003% \t9 \t14.1% \t9 \t14.1%\n",
    "    3 \tTotal Cohort \t01M292 \tHENRY STREET SCHOOL FOR INTERNATIONAL \t2006 \t78 \t43 \t55.1% \t36 \t46.2% \t83.7% \t... \t36 \t46.2% \t83.7% \t7 \t9% \t16.3% \t16 \t20.5% \t11 \t14.1%\n",
    "    4 \tTotal Cohort \t01M292 \tHENRY STREET SCHOOL FOR INTERNATIONAL \t2006 Aug \t78 \t44 \t56.4% \t37 \t47.4% \t84.1% \t... \t37 \t47.4% \t84.1% \t7 \t9% \t15.9% \t15 \t19.2% \t11 \t14.1%\n",
    "\n",
    "The Demographic and Cohort columns are what prevent DBN from being unique in the graduation data. A Cohort appears to refer to the year the data represents, and the Demographic appears to refer to a specific demographic group. In this case, we want to pick data from the most recent Cohort available, which is 2006. We also want data from the full cohort, so we'll only pick rows where Demographic is Total Cohort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9: Condensing the Graduation Data Set\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Filter graduation, only selecting rows where the Cohort column equals 2006.\n",
    "    Filter graduation, only selecting rows where the Demographic column equals Total Cohort.\n",
    "    Display the first few rows of data[\"graduation\"] to verify that everything worked properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Demographic     DBN                            School Name Cohort  \\\n",
      "3   Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL   2006   \n",
      "10  Total Cohort  01M448    UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   2006   \n",
      "17  Total Cohort  01M450             EAST SIDE COMMUNITY SCHOOL   2006   \n",
      "24  Total Cohort  01M509                MARTA VALLE HIGH SCHOOL   2006   \n",
      "31  Total Cohort  01M515  LOWER EAST SIDE PREPARATORY HIGH SCHO   2006   \n",
      "\n",
      "    Total Cohort Total Grads - n Total Grads - % of cohort Total Regents - n  \\\n",
      "3             78              43                     55.1%                36   \n",
      "10           124              53                     42.7%                42   \n",
      "17            90              70                     77.8%                67   \n",
      "24            84              47                       56%                40   \n",
      "31           193             105                     54.4%                91   \n",
      "\n",
      "   Total Regents - % of cohort Total Regents - % of grads  \\\n",
      "3                        46.2%                      83.7%   \n",
      "10                       33.9%                      79.2%   \n",
      "17         74.400000000000006%                      95.7%   \n",
      "24                       47.6%                      85.1%   \n",
      "31                       47.2%                      86.7%   \n",
      "\n",
      "              ...            Regents w/o Advanced - n  \\\n",
      "3             ...                                  36   \n",
      "10            ...                                  34   \n",
      "17            ...                                  67   \n",
      "24            ...                                  23   \n",
      "31            ...                                  22   \n",
      "\n",
      "   Regents w/o Advanced - % of cohort Regents w/o Advanced - % of grads  \\\n",
      "3                               46.2%                             83.7%   \n",
      "10                              27.4%                             64.2%   \n",
      "17                74.400000000000006%                             95.7%   \n",
      "24                              27.4%                             48.9%   \n",
      "31                              11.4%                               21%   \n",
      "\n",
      "   Local - n Local - % of cohort Local - % of grads Still Enrolled - n  \\\n",
      "3          7                  9%              16.3%                 16   \n",
      "10        11                8.9%              20.8%                 46   \n",
      "17         3                3.3%               4.3%                 15   \n",
      "24         7  8.300000000000001%              14.9%                 25   \n",
      "31        14                7.3%              13.3%                 53   \n",
      "\n",
      "   Still Enrolled - % of cohort Dropped Out - n Dropped Out - % of cohort  \n",
      "3                         20.5%              11                     14.1%  \n",
      "10                        37.1%              20       16.100000000000001%  \n",
      "17                        16.7%               5                      5.6%  \n",
      "24                        29.8%               5                        6%  \n",
      "31                        27.5%              35       18.100000000000001%  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "graduation = data['graduation']\n",
    "\n",
    "graduation = graduation[ graduation['Cohort'] == \"2006\" ]\n",
    "graduation = graduation[ graduation['Demographic'] == 'Total Cohort' ]\n",
    "\n",
    "data['graduation'] = graduation\n",
    "print ( data['graduation'].head( 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10: Converting AP Test Scores\n",
    "\n",
    "We're almost ready to combine all of the data sets. The only remaining thing to do is convert the Advanced Placement (AP) test scores from strings to numeric values. High school students take the AP exams before applying to college. There are several AP exams, each corresponding to a school subject. High school students who earn high scores may receive college credit.\n",
    "\n",
    "AP exams have a 1 to 5 scale; 3 or higher is a passing score. Many high school students take AP exams -- particularly those who attend academically challenging institutions. AP exams are much more rare in schools that lack funding or academic rigor.\n",
    "\n",
    "It will be interesting to find out whether AP exam scores are correlated with SAT scores across high schools. To determine this, we'll need to convert the AP exam scores in the ap_2010 data set to numeric values first.\n",
    "\n",
    "There are three columns we'll need to convert:\n",
    "\n",
    "    AP Test Takers (note that there's a trailing space in the column name)\n",
    "    Total Exams Taken\n",
    "    Number of Exams with scores 3 4 or 5\n",
    "\n",
    "Note that the first column name above, AP Test Takers, has a trailing space at the end.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Convert each of the following columns in ap_2010 to numeric values using the pandas.to_numeric() function with the keyword argument errors=\"coerce\".\n",
    "        AP Test Takers\n",
    "        Total Exams Taken\n",
    "        Number of Exams with scores 3 4 or 5\n",
    "    Display the first few rows of ap_2010 to confirm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN                             SchoolName  AP Test Takers   \\\n",
      "0  01M448           UNIVERSITY NEIGHBORHOOD H.S.             39.0   \n",
      "1  01M450                 EAST SIDE COMMUNITY HS             19.0   \n",
      "2  01M515                    LOWER EASTSIDE PREP             24.0   \n",
      "3  01M539         NEW EXPLORATIONS SCI,TECH,MATH            255.0   \n",
      "4  02M296  High School of Hospitality Management              NaN   \n",
      "\n",
      "   Total Exams Taken  Number of Exams with scores 3 4 or 5  \n",
      "0               49.0                                  10.0  \n",
      "1               21.0                                   NaN  \n",
      "2               26.0                                  24.0  \n",
      "3              377.0                                 191.0  \n",
      "4                NaN                                   NaN  \n"
     ]
    }
   ],
   "source": [
    "cols = ['AP Test Takers ', 'Total Exams Taken', 'Number of Exams with scores 3 4 or 5']\n",
    "for col in cols:\n",
    "    data[\"ap_2010\"][col] = pd.to_numeric(data[\"ap_2010\"][col], errors=\"coerce\")\n",
    "    \n",
    "print(data[\"ap_2010\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1: Left, Right, Inner, and Outer Joins\n",
    "\n",
    "Before we merge our data, we'll need to decide on the merge strategy we want to use. We'll be using the pandas pandas.DataFrame.merge() function, which supports four types of joins -- left, right, inner, and outer. Each of these join types dictates how pandas combines the rows.\n",
    "\n",
    "We'll be using the DBN column to identify matching rows across data sets. In other words, the values in that column will help us know which row from the first data set to combine with which row in the second data set.\n",
    "\n",
    "There may be DBN values that exist in one data set but not in another. This is partly because the data is from different years. Each data set also has inconsistencies in terms of how it was gathered. Human error (and other types of errors) may also play a role. Therefore, we may not find matches for the DBN values in sat_results in all of the other data sets, and other data sets may have DBN values that don't exist in sat_results.\n",
    "\n",
    "We'll merge two data sets at a time. For example, we'll merge sat_results and hs_directory, then merge the result with ap_2010, then merge the result of that with class_size. We'll continue combining data sets in this way until we've merged all of them. Afterwards, we'll have roughly the same number of rows, but each row will have columns from all of the data sets.\n",
    "\n",
    "The merge strategy we pick will affect the number of rows we end up with. Let's take a look at each strategy.\n",
    "\n",
    "Let's say we're merging the following two data sets:\n",
    "\n",
    "- With an inner merge, we'd only combine rows where the same DBN exists in both data sets. We'd end up with this result:\n",
    "\n",
    "- With a left merge, we'd only use DBN values from the dataframe on the \"left\" of the merge. In this case, sat_results is on the left. Some of the DBNs in sat_results don't exist in class_size, though. The merge will handle this by assiging null values to the columns in sat_results that don't have corresponding data in class_size.\n",
    "\n",
    "- With a right merge, we'll only use DBN values from the dataframe on the \"right\" of the merge. In this case, class_size is on the right\n",
    "\n",
    "- With an outer merge, we'll take any DBN values from either sat_results or class_size:\n",
    "\n",
    "As you can see, each merge strategy has its advantages. Depending on the strategy we choose, we may preserve rows at the expense of having more missing column data, or minimize missing data at the expense of having fewer rows. Choosing a merge strategy is an important decision; it's worth thinking about your data carefully, and what trade-offs you're willing to make.\n",
    "\n",
    "Because this project is concerned with determing demographic factors that correlate with SAT score, we'll want to preserve as many rows as possible from sat_results while minimizing null values.\n",
    "\n",
    "This means that we may need to use different merge strategies with different data sets. Some of the data sets have a lot of missing DBN values. This makes a left join more appropriate, because we don't want to lose too many rows when we merge. If we did an inner join, we would lose the data for many high schools.\n",
    "\n",
    "Some data sets have DBN values that are almost identical to those in sat_results. Those data sets also have information we need to keep. Most of our analysis would be impossible if a significant number of rows was missing from demographics, for example. Therefore, we'll do an inner join to avoid missing data in these columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12: Performing the Left Joins\n",
    "\n",
    "Both the ap_2010 and the graduation data sets have many missing DBN values, so we'll use a left join when we merge the sat_results data set with them. Because we're using a left join, our final dataframe will have all of the same DBN values as the original sat_results dataframe.\n",
    "\n",
    "We'll need to use the pandas df.merge() method to merge dataframes. The \"left\" dataframe is the one we call the method on, and the \"right\" dataframe is the one we pass into df.merge().\n",
    "\n",
    "Because we're using the DBN column to join the dataframes, we'll need to specify the keyword argument on=\"DBN\" when calling pandas.DataFrame..merge().\n",
    "\n",
    "First, we'll assign data[\"sat_results\"] to the variable combined. Then, we'll merge all of the other dataframes with combined. When we're finished, combined will have all of the columns from all of the data sets.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Use the pandas pandas.DataFrame.merge() method to merge the ap_2010 data set into combined.\n",
    "        Make sure to specify how=\"left\" as a keyword argument to indicate the correct join type.\n",
    "        Make sure to assign the result of the merge operation back to combined.\n",
    "    Use the pandas df.merge() method to merge the graduation data set into combined.\n",
    "        Make sure to specify how=\"left\" as a keyword argument to get the correct join type.\n",
    "        Make sure to assign the result of the merge operation back to combined.\n",
    "    Display the first few rows of combined to verify that the correct operations occurred.\n",
    "    Use the pandas.DataFrame.shape() method to display the shape of the dataframe and see how many rows now exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN                                    SCHOOL NAME  \\\n",
      "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
      "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
      "\n",
      "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
      "0                     29                             355                 404   \n",
      "1                     91                             383                 423   \n",
      "2                     70                             377                 402   \n",
      "3                      7                             414                 401   \n",
      "4                     44                             390                 433   \n",
      "\n",
      "  SAT Writing Avg. Score                    SchoolName  AP Test Takers   \\\n",
      "0                    363                           NaN              NaN   \n",
      "1                    366  UNIVERSITY NEIGHBORHOOD H.S.             39.0   \n",
      "2                    370        EAST SIDE COMMUNITY HS             19.0   \n",
      "3                    359                           NaN              NaN   \n",
      "4                    384                           NaN              NaN   \n",
      "\n",
      "   Total Exams Taken  Number of Exams with scores 3 4 or 5  \\\n",
      "0                NaN                                   NaN   \n",
      "1               49.0                                  10.0   \n",
      "2               21.0                                   NaN   \n",
      "3                NaN                                   NaN   \n",
      "4                NaN                                   NaN   \n",
      "\n",
      "             ...            Regents w/o Advanced - n  \\\n",
      "0            ...                                  36   \n",
      "1            ...                                  34   \n",
      "2            ...                                  67   \n",
      "3            ...                                 NaN   \n",
      "4            ...                                  23   \n",
      "\n",
      "  Regents w/o Advanced - % of cohort Regents w/o Advanced - % of grads  \\\n",
      "0                              46.2%                             83.7%   \n",
      "1                              27.4%                             64.2%   \n",
      "2                74.400000000000006%                             95.7%   \n",
      "3                                NaN                               NaN   \n",
      "4                              27.4%                             48.9%   \n",
      "\n",
      "   Local - n Local - % of cohort Local - % of grads Still Enrolled - n  \\\n",
      "0          7                  9%              16.3%                 16   \n",
      "1         11                8.9%              20.8%                 46   \n",
      "2          3                3.3%               4.3%                 15   \n",
      "3        NaN                 NaN                NaN                NaN   \n",
      "4          7  8.300000000000001%              14.9%                 25   \n",
      "\n",
      "  Still Enrolled - % of cohort Dropped Out - n Dropped Out - % of cohort  \n",
      "0                        20.5%              11                     14.1%  \n",
      "1                        37.1%              20       16.100000000000001%  \n",
      "2                        16.7%               5                      5.6%  \n",
      "3                          NaN             NaN                       NaN  \n",
      "4                        29.8%               5                        6%  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(479, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = data['sat_results']\n",
    "combined = combined.merge( data['ap_2010'], on='DBN', how='left' )\n",
    "combined = combined.merge( data['graduation'], on='DBN', how='left' )\n",
    "print ( combined.head( 5 ) )\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13: Performing the Inner Joins\n",
    "\n",
    "Now that we've performed the left joins, we still have to merge class_size, demographics, survey, and hs_directory into combined. Because these files contain information that's more valuable to our analysis and also have fewer missing DBN values, we'll use the inner join type.\n",
    "\n",
    "# Instructions\n",
    "\n",
    "    Merge class_size into combined. Then, merge class_size, demographics, survey, and hs_directory into combined one by one, in that order.\n",
    "        Be sure to follow the exact order above.\n",
    "        Remember to specify the correct column to join on, as well as the correct join type.\n",
    "    Display the first few rows of combined to verify that the correct operations occurred.\n",
    "    Call pandas.DataFrame.shape() to display the shape of the dataframe to see how many rows now exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_survey = pd.read_csv( \"../data/survey_all.txt\", delimiter=\"\\t\", encoding=\"windows-1252\" )\n",
    "d75_survey = pd.read_csv( \"../data/survey_d75.txt\", delimiter=\"\\t\", encoding=\"windows-1252\" )\n",
    "\n",
    "survey = pd.concat( [ all_survey, d75_survey ] , axis=0 )\n",
    "# survey.head( 5 )\n",
    "\n",
    "survey[\"DBN\"] = survey[\"dbn\"]\n",
    "survey_cols = [\"DBN\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\", \"com_p_11\", \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\", \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n",
    "[\"dbn\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\", \"com_p_11\", \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\", \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n",
    "\n",
    "data['survey'] = survey.loc[:,survey_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN                                        SCHOOL NAME  \\\n",
      "0  01M292      HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448                UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                         EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M509                            MARTA VALLE HIGH SCHOOL   \n",
      "4  01M539  NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...   \n",
      "\n",
      "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
      "0                     29                             355                 404   \n",
      "1                     91                             383                 423   \n",
      "2                     70                             377                 402   \n",
      "3                     44                             390                 433   \n",
      "4                    159                             522                 574   \n",
      "\n",
      "  SAT Writing Avg. Score                      SchoolName  AP Test Takers   \\\n",
      "0                    363                             NaN              NaN   \n",
      "1                    366    UNIVERSITY NEIGHBORHOOD H.S.             39.0   \n",
      "2                    370          EAST SIDE COMMUNITY HS             19.0   \n",
      "3                    384                             NaN              NaN   \n",
      "4                    525  NEW EXPLORATIONS SCI,TECH,MATH            255.0   \n",
      "\n",
      "   Total Exams Taken  Number of Exams with scores 3 4 or 5  \\\n",
      "0                NaN                                   NaN   \n",
      "1               49.0                                  10.0   \n",
      "2               21.0                                   NaN   \n",
      "3                NaN                                   NaN   \n",
      "4              377.0                                 191.0   \n",
      "\n",
      "                         ...                          \\\n",
      "0                        ...                           \n",
      "1                        ...                           \n",
      "2                        ...                           \n",
      "3                        ...                           \n",
      "4                        ...                           \n",
      "\n",
      "                                          priority02  \\\n",
      "0  Then to Manhattan students or residents who at...   \n",
      "1  For M35B only: Open only to students whose hom...   \n",
      "2                    Then to New York City residents   \n",
      "3            Then to Manhattan students or residents   \n",
      "4                    Then to New York City residents   \n",
      "\n",
      "                                          priority03  \\\n",
      "0  Then to New York City residents who attend an ...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3                    Then to New York City residents   \n",
      "4                                                NaN   \n",
      "\n",
      "                                priority04                       priority05  \\\n",
      "0  Then to Manhattan students or residents  Then to New York City residents   \n",
      "1                                      NaN                              NaN   \n",
      "2                                      NaN                              NaN   \n",
      "3                                      NaN                              NaN   \n",
      "4                                      NaN                              NaN   \n",
      "\n",
      "  priority06 priority07 priority08 priority09 priority10  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN        NaN        NaN   \n",
      "2        NaN        NaN        NaN        NaN        NaN   \n",
      "3        NaN        NaN        NaN        NaN        NaN   \n",
      "4        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "                                          Location 1  \n",
      "0  220 Henry Street\\nNew York, NY 10002\\n(40.7137...  \n",
      "1  200 Monroe Street\\nNew York, NY 10002\\n(40.712...  \n",
      "2  420 East 12 Street\\nNew York, NY 10009\\n(40.72...  \n",
      "3  145 Stanton Street\\nNew York, NY 10002\\n(40.72...  \n",
      "4  111 Columbia Street\\nNew York, NY 10002\\n(40.7...  \n",
      "\n",
      "[5 rows x 156 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(363, 156)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = combined.merge( data['class_size'], on='DBN', how='inner' )\n",
    "combined = combined.merge( data['demographics'], on='DBN', how='inner' )\n",
    "combined = combined.merge( data['survey'], on='DBN', how='inner' )\n",
    "combined = combined.merge( data['hs_directory'], on='DBN', how='inner' )\n",
    "print( combined.head() )\n",
    "combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14: Filling in Missing Values\n",
    "\n",
    "You may have noticed that the inner joins resulted in 116 fewer rows in sat_results. This is because pandas couldn't find the DBN values that existed in sat_results in the other data sets. While this is worth investigating, we're currently looking for high-level correlations, so we don't need to dive into which DBNs are missing.\n",
    "\n",
    "You may also have noticed that we now have many columns with null (NaN) values. This is because we chose to do left joins, where some columns may not have had data. The data set also had some missing values to begin with. If we hadn't performed a left join, all of the rows with missing data would have been lost in the merge process, which wouldn't have left us with many high schools in our data set.\n",
    "\n",
    "There are several ways to handle missing data, and we'll cover them in more detail later on. For now, we'll just fill in the missing values with the overall mean for the column, like so:\n",
    "\n",
    "In the diagram above, the mean of the first column is (1800 + 1600 + 2200 + 2300) / 4, or 1975, and the mean of the second column is (20 + 30 + 30 + 50) / 4, or 32.5. We replace the missing values with the means of their respective columns, which allows us to proceed with analyses that can't handle missing values (like correlations).\n",
    "\n",
    "We can fill in missing data in pandas using the pandas.DataFrame.fillna() method. This method will replace any missing values in a dataframe with the values we specify. We can compute the mean of every column using the pandas.DataFrame.mean() method. If we pass the results of the df.mean() method into the df.fillna() method, pandas will fill in the missing values in each column with the mean of that column.\n",
    "\n",
    "Here's an example of how we would accomplish this:\n",
    "\n",
    "    means = df.mean()\n",
    "\n",
    "    df = df.fillna(means)\n",
    "\n",
    "Note that if a column consists entirely of null or NaN values, pandas won't be able to fill in the missing values when we use the df.fillna() method along with the df.mean() method, because there won't be a mean.\n",
    "\n",
    "We should fill any NaN or null values that remain after the initial replacement with the value 0. We can do this by passing 0 into the df.fillna() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15: Filling in Missing Values\n",
    "\n",
    "# Instructions\n",
    "\n",
    "    Calculate the means of all of the columns in combined using the pandas.DataFrame.mean() method.\n",
    "    Fill in any missing values in combined with the means of the respective columns using the pandas.DataFrame.fillna() method.\n",
    "    Fill in any remaining missing values in combined with 0 using the df.fillna() method.\n",
    "    Display the first few rows of combined to verify that the correct operations occurred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBN</th>\n",
       "      <th>SCHOOL NAME</th>\n",
       "      <th>Num of SAT Test Takers</th>\n",
       "      <th>SAT Critical Reading Avg. Score</th>\n",
       "      <th>SAT Math Avg. Score</th>\n",
       "      <th>SAT Writing Avg. Score</th>\n",
       "      <th>SchoolName</th>\n",
       "      <th>AP Test Takers</th>\n",
       "      <th>Total Exams Taken</th>\n",
       "      <th>Number of Exams with scores 3 4 or 5</th>\n",
       "      <th>...</th>\n",
       "      <th>priority02</th>\n",
       "      <th>priority03</th>\n",
       "      <th>priority04</th>\n",
       "      <th>priority05</th>\n",
       "      <th>priority06</th>\n",
       "      <th>priority07</th>\n",
       "      <th>priority08</th>\n",
       "      <th>priority09</th>\n",
       "      <th>priority10</th>\n",
       "      <th>Location 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01M292</td>\n",
       "      <td>HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES</td>\n",
       "      <td>29</td>\n",
       "      <td>355</td>\n",
       "      <td>404</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>129.028846</td>\n",
       "      <td>197.038462</td>\n",
       "      <td>153.45</td>\n",
       "      <td>...</td>\n",
       "      <td>Then to Manhattan students or residents who at...</td>\n",
       "      <td>Then to New York City residents who attend an ...</td>\n",
       "      <td>Then to Manhattan students or residents</td>\n",
       "      <td>Then to New York City residents</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>220 Henry Street\\nNew York, NY 10002\\n(40.7137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01M448</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n",
       "      <td>91</td>\n",
       "      <td>383</td>\n",
       "      <td>423</td>\n",
       "      <td>366</td>\n",
       "      <td>UNIVERSITY NEIGHBORHOOD H.S.</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>For M35B only: Open only to students whose hom...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200 Monroe Street\\nNew York, NY 10002\\n(40.712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01M450</td>\n",
       "      <td>EAST SIDE COMMUNITY SCHOOL</td>\n",
       "      <td>70</td>\n",
       "      <td>377</td>\n",
       "      <td>402</td>\n",
       "      <td>370</td>\n",
       "      <td>EAST SIDE COMMUNITY HS</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>153.45</td>\n",
       "      <td>...</td>\n",
       "      <td>Then to New York City residents</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>420 East 12 Street\\nNew York, NY 10009\\n(40.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01M509</td>\n",
       "      <td>MARTA VALLE HIGH SCHOOL</td>\n",
       "      <td>44</td>\n",
       "      <td>390</td>\n",
       "      <td>433</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>129.028846</td>\n",
       "      <td>197.038462</td>\n",
       "      <td>153.45</td>\n",
       "      <td>...</td>\n",
       "      <td>Then to Manhattan students or residents</td>\n",
       "      <td>Then to New York City residents</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145 Stanton Street\\nNew York, NY 10002\\n(40.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01M539</td>\n",
       "      <td>NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...</td>\n",
       "      <td>159</td>\n",
       "      <td>522</td>\n",
       "      <td>574</td>\n",
       "      <td>525</td>\n",
       "      <td>NEW EXPLORATIONS SCI,TECH,MATH</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>191.00</td>\n",
       "      <td>...</td>\n",
       "      <td>Then to New York City residents</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111 Columbia Street\\nNew York, NY 10002\\n(40.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DBN                                        SCHOOL NAME  \\\n",
       "0  01M292      HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
       "1  01M448                UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
       "2  01M450                         EAST SIDE COMMUNITY SCHOOL   \n",
       "3  01M509                            MARTA VALLE HIGH SCHOOL   \n",
       "4  01M539  NEW EXPLORATIONS INTO SCIENCE, TECHNOLOGY AND ...   \n",
       "\n",
       "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
       "0                     29                             355                 404   \n",
       "1                     91                             383                 423   \n",
       "2                     70                             377                 402   \n",
       "3                     44                             390                 433   \n",
       "4                    159                             522                 574   \n",
       "\n",
       "  SAT Writing Avg. Score                      SchoolName  AP Test Takers   \\\n",
       "0                    363                               0       129.028846   \n",
       "1                    366    UNIVERSITY NEIGHBORHOOD H.S.        39.000000   \n",
       "2                    370          EAST SIDE COMMUNITY HS        19.000000   \n",
       "3                    384                               0       129.028846   \n",
       "4                    525  NEW EXPLORATIONS SCI,TECH,MATH       255.000000   \n",
       "\n",
       "   Total Exams Taken  Number of Exams with scores 3 4 or 5  \\\n",
       "0         197.038462                                153.45   \n",
       "1          49.000000                                 10.00   \n",
       "2          21.000000                                153.45   \n",
       "3         197.038462                                153.45   \n",
       "4         377.000000                                191.00   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                          priority02  \\\n",
       "0  Then to Manhattan students or residents who at...   \n",
       "1  For M35B only: Open only to students whose hom...   \n",
       "2                    Then to New York City residents   \n",
       "3            Then to Manhattan students or residents   \n",
       "4                    Then to New York City residents   \n",
       "\n",
       "                                          priority03  \\\n",
       "0  Then to New York City residents who attend an ...   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                    Then to New York City residents   \n",
       "4                                                  0   \n",
       "\n",
       "                                priority04                       priority05  \\\n",
       "0  Then to Manhattan students or residents  Then to New York City residents   \n",
       "1                                        0                                0   \n",
       "2                                        0                                0   \n",
       "3                                        0                                0   \n",
       "4                                        0                                0   \n",
       "\n",
       "  priority06 priority07 priority08 priority09 priority10  \\\n",
       "0          0          0          0          0          0   \n",
       "1          0          0          0          0          0   \n",
       "2          0          0          0          0          0   \n",
       "3          0          0          0          0          0   \n",
       "4          0          0          0          0          0   \n",
       "\n",
       "                                          Location 1  \n",
       "0  220 Henry Street\\nNew York, NY 10002\\n(40.7137...  \n",
       "1  200 Monroe Street\\nNew York, NY 10002\\n(40.712...  \n",
       "2  420 East 12 Street\\nNew York, NY 10009\\n(40.72...  \n",
       "3  145 Stanton Street\\nNew York, NY 10002\\n(40.72...  \n",
       "4  111 Columbia Street\\nNew York, NY 10002\\n(40.7...  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = combined.mean()\n",
    "combined = combined.fillna( mean )\n",
    "combined = combined.fillna( 0 )\n",
    "combined.head( 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16: Adding a School District Column for Mapping\n",
    "\n",
    "We've finished cleaning and combining our data! We now have a clean data set on which we can base our analysis. Mapping the statistics out on a school district level might be an interesting way to analyze them. Adding a column to the data set that specifies the school district will help us accomplish this.\n",
    "\n",
    "The school district is just the first two characters of the DBN. We can apply a function over the DBN column of combined that pulls out the first two letters.\n",
    "\n",
    "For example, we can use indexing to extract the first few characters of a string, like this:\n",
    "\n",
    "name = \"Sinbad\"\n",
    "\n",
    "print(name[0:2])\n",
    "\n",
    "# Instructions\n",
    "\n",
    "    Write a function that extracts the first two characters of a string and returns them.\n",
    "    Apply the function to the DBN column of combined, and assign the result to the school_dist column of combined.\n",
    "    Display the first few items in the school_dist column of combined to verify the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363, 157)\n"
     ]
    }
   ],
   "source": [
    "def firsttwo( input ):\n",
    "    return input[0:2]\n",
    "\n",
    "combined['school_dict'] = combined['DBN'].apply( firsttwo )\n",
    "print( combined.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 17: Next Steps\n",
    "\n",
    "We now have a clean data set we can analyze! We've done a lot in this mission. We've gone from having several messy sources to one clean, combined, data set that's ready for analysis.\n",
    "\n",
    "Along the way, we've learned about:\n",
    "\n",
    "    How to handle missing values\n",
    "    Different types of merges\n",
    "    How to condense data sets\n",
    "    How to compute averages across dataframes\n",
    "\n",
    "Data scientists rarely start out with tidy data sets, which makes cleaning and combining them one of the most critical skills any data professional can learn.\n",
    "\n",
    "In the next mission, we'll analyze our clean data to find correlations and create maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
