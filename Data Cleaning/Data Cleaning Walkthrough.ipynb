{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Introduction\n",
    "\n",
    "At many points in your career, you'll need to be able to build complete, end-to-end data science projects on your own. Data science projects usually consist of one of two things:\n",
    "\n",
    "- An exploration and analysis of a set of data. One example might involve analyzing donors to political campaigns, creating a plot, and then sharing an analysis of the plot with others.\n",
    "- An operational system that generates predictions based on data that updates continually. An algorithm that pulls in daily stock ticker data and predicts which stock prices will rise and fall would be one example.\n",
    "\n",
    "You'll find the ability to create data science projects useful in several different contexts:\n",
    "\n",
    "- Projects will help you build a portfolio, which is critical to finding a job as a data analyst or scientist.\n",
    "- Working on projects will help you learn new skills and reinforce existing concepts.\n",
    "- Most \"real-world\" data science and analysis work consists of developing internal projects.\n",
    "- Projects allow you to investigate interesting phenomena and satisfy your curiosity.\n",
    "\n",
    "Whether you aim to become a data scientist or analyst or you're just curious about the world, building projects can be immensely rewarding.\n",
    "\n",
    "Here's an example of a finished project.\n",
    "\n",
    "In this mission, we'll walk through the first part of a complete data science project, including how to acquire the raw data. The project will focus on exploring and analyzing a data set. We'll develop our data cleaning and storytelling skills, which will enable us to build complete projects on our own.\n",
    "\n",
    "We'll focus primarily on data exploration in this mission. We'll also combine several messy data sets into a single clean one to make analysis easier. Over the next few missions, we'll work through the rest of our project and perform the actual analysis.\n",
    "\n",
    "The first step in creating a project is to decide on a topic. You want the topic to be something you're interested in and motivated to explore. It's very obvious when people are making projects just to make them, rather than out of a genuine interest in the topic.\n",
    "\n",
    "Here are two ways to go about finding a good topic:\n",
    "\n",
    "- Think about what sectors or angles you're really interested in, then find data sets relating to those sectors.\n",
    "- Review several data sets, and find one that seems interesting enough to explore.\n",
    "\n",
    "Whichever approach you take, you can start your search at these sites:\n",
    "\n",
    "- [Data.gov](https://www.data.gov/) - A directory of government data downloads\n",
    "- [/r/datasets](https://reddit.com/r/datasets) - A subreddit that has hundreds of interesting data sets\n",
    "- [Awesome datasets](https://github.com/caesar0301/awesome-public-datasets) - A list of data sets hosted on GitHub\n",
    "- [rs.io](http://rs.io/100-interesting-data-sets-for-statistics/) - A great blog post with hundreds of interesting data sets\n",
    "\n",
    "In real-world data science, you may not find an ideal data set. You might have to aggregate disparate data sources instead, or do a good amount of data cleaning.\n",
    "\n",
    "For the purposes of this project, we'll be using data about New York City public schools, which can be found [here](https://data.cityofnewyork.us/browse?category=Education).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Finding All of the Relevant Data Sets\n",
    "\n",
    "Once you've chosen a topic, you'll want to pick an angle to investigate. It's important to choose an angle that has enough depth to analyze, but isn't so complicated that it's difficult to get started. You want to finish the project, and you want your results to be interesting to others.\n",
    "\n",
    "One of the most controversial issues in the U.S. educational system is the efficacy of standardized tests, and whether they're unfair to certain groups. Given our prior knowledge of this topic, investigating the correlations between SAT scores and demographics might be an interesting angle to take. We could correlate SAT scores with factors like race, gender, income, and more.\n",
    "\n",
    "The SAT, or Scholastic Aptitude Test, is an exam that U.S. high school students take before applying to college. Colleges take the test scores into account when deciding who to admit, so it's fairly important to perform well on it.\n",
    "\n",
    "The test consists of three sections, each of which has 800 possible points. The combined score is out of 2,400 possible points (while this number has changed a few times, the data set for our project is based on 2,400 total points). Organizations often rank high schools by their average SAT scores. The scores are also considered a measure of overall school district quality.\n",
    "\n",
    "New York City makes its data on high school SAT scores available online, as well as the demographics for each high school. The first few rows of the SAT data look like this:\n",
    "\n",
    "<img src='sat.png'>\n",
    "\n",
    "Unfortunately, combining both of the data sets won't give us all of the demographic information we want to use. We'll need to supplement our data with other sources to do our full analysis.\n",
    "\n",
    "The same website has several related data sets covering demographic information and test scores. Here are the links to all of the data sets we'll be using:\n",
    "\n",
    "- SAT scores by school - SAT scores for each high school in New York City\n",
    "- School attendance - Attendance information for each school in New York City\n",
    "- Class size - Information on class size for each school\n",
    "- AP test results - Advanced Placement (AP) exam results for each high school (passing an optional AP exam in a particular subject can earn a student college credit in that subject)\n",
    "- Graduation outcomes - The percentage of students who graduated, and other outcome information\n",
    "- Demographics - Demographic information for each school\n",
    "- School survey - Surveys of parents, teachers, and students at each school\n",
    "\n",
    "All of these data sets are interrelated. We'll need to combine them into a single data set before we can find correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Finding Background Information\n",
    "\n",
    "Before we move into coding, we'll need to do some background research. A thorough understanding of the data will help us avoid costly mistakes, such as thinking that a column represents something other than what it does. Background research will also give us a better understanding of how to combine and analyze the data.\n",
    "\n",
    "In this case, we'll want to research:\n",
    "\n",
    "    New York City\n",
    "    The SAT\n",
    "    Schools in New York City\n",
    "    Our data\n",
    "\n",
    "We can learn a few different things from these resources. For example:\n",
    "\n",
    "- Only high school students take the SAT, so we'll want to focus on high schools.\n",
    "- New York City is made up of five boroughs, which are essentially distinct regions.\n",
    "- New York City schools fall within several different school districts, each of which can contains dozens of schools.\n",
    "- Our data sets include several different types of schools. We'll need to clean them so that we can focus on high schools only.\n",
    "- Each school in New York City has a unique code called a DBN, or district borough number.\n",
    "- Aggregating data by district will allow us to use the district mapping data to plot district-by-district differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Reading in the Data\n",
    "\n",
    "Once we've done our background research, we're ready to read in the data. For your convenience, we've placed all the data into the schools folder. Here are all of the files in the folder:\n",
    "\n",
    "    ap_2010.csv - Data on AP test results\n",
    "    class_size.csv - Data on class size\n",
    "    demographics.csv - Data on demographics\n",
    "    graduation.csv - Data on graduation outcomes\n",
    "    hs_directory.csv - A directory of high schools\n",
    "    sat_results.csv - Data on SAT scores\n",
    "    survey_all.txt - Data on surveys from all schools\n",
    "    survey_d75.txt - Data on surveys from New York City district 75\n",
    "\n",
    "survey_all.txt and survey_d75.txt are in more complicated formats than the other files. For now, we'll focus on reading in the CSV files only, and then explore them.\n",
    "\n",
    "We'll read each file into a pandas dataframe, and then store all of the dataframes in a dictionary. This will give us a convenient way to store them, and a quick way to reference them later on.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Read each of the files in the list data_files into a pandas dataframe using the pandas.read_csv() function.\n",
    "        Recall that all of the data sets are in the schools folder. That means the path to ap_2010.csv is schools/ap_2010.csv.\n",
    "    Add each of the dataframes to the dictionary data, using the base of the filename as the key. For example, you'd enter ap_2010 for the file ap_2010.csv.\n",
    "    Afterwards, data should have the following keys:\n",
    "        ap_2010\n",
    "        class_size\n",
    "        demographics\n",
    "        graduation\n",
    "        hs_directory\n",
    "        sat_results\n",
    "    In addition, each key in data should have the corresponding dataframe as its value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "data = {}\n",
    "\n",
    "for file in data_files:\n",
    "    df = pd.read_csv( \"../data/\" + file )\n",
    "    data[file.split( \".\" )[0]] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes about data\n",
    "\n",
    "## ap_2010\n",
    "\n",
    "- AP ( Advanced Placement is a subject dependent tets of advanced nature )\n",
    "- Same student can take AP test in multiple subjects, hence 'Total Exams Taken' is a differnt field altogether\n",
    "\n",
    "## class_size\n",
    "\n",
    "- This datda contains class specific records, locality information is also present\n",
    "\n",
    "## demographics\n",
    "\n",
    "- Contains data about the demographics of the school( racial distribution, male/female )\n",
    "\n",
    "## graduation\n",
    "\n",
    "- People who dropped out, year, how many graduated etc\n",
    "\n",
    "## hs_directory\n",
    "- Address, phone number basically at lot of extra information \n",
    "\n",
    "## sat_results\n",
    "- The most important data we are intrested in number of sat takers in school, marks etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Exploring the SAT Data\n",
    "\n",
    "What we're mainly interested in is the SAT data set, which corresponds to the dictionary key sat_results. This data set contains the SAT scores for each high school in New York City. We eventually want to correlate selected information from this data set with information in the other data sets.\n",
    "\n",
    "Let's explore sat_results to see what we can discover. Exploring the dataframe will help us understand the structure of the data, and make it easier for us to analyze it.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Display the first five rows of the SAT scores data.\n",
    "        Use the key sat_results to access the SAT scores dataframe stored in the dictionary data.\n",
    "        Use the pandas.DataFrame.head() method along with the print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN                                    SCHOOL NAME  \\\n",
      "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
      "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
      "\n",
      "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
      "0                     29                             355                 404   \n",
      "1                     91                             383                 423   \n",
      "2                     70                             377                 402   \n",
      "3                      7                             414                 401   \n",
      "4                     44                             390                 433   \n",
      "\n",
      "  SAT Writing Avg. Score  \n",
      "0                    363  \n",
      "1                    366  \n",
      "2                    370  \n",
      "3                    359  \n",
      "4                    384  \n"
     ]
    }
   ],
   "source": [
    "print ( data['sat_results'].head( 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Exploring the Remaining Data\n",
    "\n",
    "When we printed the first five rows of the SAT data, the output looked like the cell above\n",
    "\n",
    "We can make a few observations based on this output:\n",
    "\n",
    "    The DBN appears to be a unique ID for each school.\n",
    "    We can tell from the first few rows of names that we only have data about high schools.\n",
    "    There's only a single row for each high school, so each DBN is unique in the SAT data.\n",
    "    We may eventually want to combine the three columns that contain SAT scores -- SAT Critical Reading Avg., Score SAT Math Avg. Score, and SAT Writing Avg. Score -- into a single column to make the scores easier to analyze.\n",
    "\n",
    "Given these observations, let's explore the other data sets to see if we can gain any insight into how to combine them.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Loop through each key in data. For each key:\n",
    "        Display the first five rows of the dataframe associated with the key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DBN                                    SCHOOL NAME  \\\n",
      "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES   \n",
      "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   \n",
      "2  01M450                     EAST SIDE COMMUNITY SCHOOL   \n",
      "3  01M458                      FORSYTH SATELLITE ACADEMY   \n",
      "4  01M509                        MARTA VALLE HIGH SCHOOL   \n",
      "\n",
      "  Num of SAT Test Takers SAT Critical Reading Avg. Score SAT Math Avg. Score  \\\n",
      "0                     29                             355                 404   \n",
      "1                     91                             383                 423   \n",
      "2                     70                             377                 402   \n",
      "3                      7                             414                 401   \n",
      "4                     44                             390                 433   \n",
      "\n",
      "  SAT Writing Avg. Score  \n",
      "0                    363  \n",
      "1                    366  \n",
      "2                    370  \n",
      "3                    359  \n",
      "4                    384  \n",
      "      DBN                       Name  schoolyear fl_percent  frl_percent  \\\n",
      "0  01M015  P.S. 015 ROBERTO CLEMENTE    20052006       89.4          NaN   \n",
      "1  01M015  P.S. 015 ROBERTO CLEMENTE    20062007       89.4          NaN   \n",
      "2  01M015  P.S. 015 ROBERTO CLEMENTE    20072008       89.4          NaN   \n",
      "3  01M015  P.S. 015 ROBERTO CLEMENTE    20082009       89.4          NaN   \n",
      "4  01M015  P.S. 015 ROBERTO CLEMENTE    20092010                    96.5   \n",
      "\n",
      "   total_enrollment prek   k grade1 grade2    ...     black_num black_per  \\\n",
      "0               281   15  36     40     33    ...            74      26.3   \n",
      "1               243   15  29     39     38    ...            68      28.0   \n",
      "2               261   18  43     39     36    ...            77      29.5   \n",
      "3               252   17  37     44     32    ...            75      29.8   \n",
      "4               208   16  40     28     32    ...            67      32.2   \n",
      "\n",
      "  hispanic_num hispanic_per white_num white_per male_num male_per female_num  \\\n",
      "0          189         67.3         5       1.8    158.0     56.2      123.0   \n",
      "1          153         63.0         4       1.6    140.0     57.6      103.0   \n",
      "2          157         60.2         7       2.7    143.0     54.8      118.0   \n",
      "3          149         59.1         7       2.8    149.0     59.1      103.0   \n",
      "4          118         56.7         6       2.9    124.0     59.6       84.0   \n",
      "\n",
      "  female_per  \n",
      "0       43.8  \n",
      "1       42.4  \n",
      "2       45.2  \n",
      "3       40.9  \n",
      "4       40.4  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "    Demographic     DBN                            School Name    Cohort  \\\n",
      "0  Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL      2003   \n",
      "1  Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL      2004   \n",
      "2  Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL      2005   \n",
      "3  Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL      2006   \n",
      "4  Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL  2006 Aug   \n",
      "\n",
      "   Total Cohort Total Grads - n Total Grads - % of cohort Total Regents - n  \\\n",
      "0             5               s                         s                 s   \n",
      "1            55              37                     67.3%                17   \n",
      "2            64              43                     67.2%                27   \n",
      "3            78              43                     55.1%                36   \n",
      "4            78              44                     56.4%                37   \n",
      "\n",
      "  Total Regents - % of cohort Total Regents - % of grads  \\\n",
      "0                           s                          s   \n",
      "1                       30.9%                      45.9%   \n",
      "2                       42.2%                      62.8%   \n",
      "3                       46.2%                      83.7%   \n",
      "4                       47.4%                      84.1%   \n",
      "\n",
      "             ...            Regents w/o Advanced - n  \\\n",
      "0            ...                                   s   \n",
      "1            ...                                  17   \n",
      "2            ...                                  27   \n",
      "3            ...                                  36   \n",
      "4            ...                                  37   \n",
      "\n",
      "  Regents w/o Advanced - % of cohort Regents w/o Advanced - % of grads  \\\n",
      "0                                  s                                 s   \n",
      "1                              30.9%                             45.9%   \n",
      "2                              42.2%                             62.8%   \n",
      "3                              46.2%                             83.7%   \n",
      "4                              47.4%                             84.1%   \n",
      "\n",
      "  Local - n Local - % of cohort   Local - % of grads Still Enrolled - n  \\\n",
      "0         s                   s                    s                  s   \n",
      "1        20               36.4%                54.1%                 15   \n",
      "2        16                 25%  37.200000000000003%                  9   \n",
      "3         7                  9%                16.3%                 16   \n",
      "4         7                  9%                15.9%                 15   \n",
      "\n",
      "  Still Enrolled - % of cohort Dropped Out - n Dropped Out - % of cohort  \n",
      "0                            s               s                         s  \n",
      "1                        27.3%               3                      5.5%  \n",
      "2                        14.1%               9                     14.1%  \n",
      "3                        20.5%              11                     14.1%  \n",
      "4                        19.2%              11                     14.1%  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "      dbn                                        school_name       boro  \\\n",
      "0  17K548                Brooklyn School for Music & Theatre   Brooklyn   \n",
      "1  09X543                   High School for Violin and Dance      Bronx   \n",
      "2  09X327        Comprehensive Model School Project M.S. 327      Bronx   \n",
      "3  02M280     Manhattan Early College School for Advertising  Manhattan   \n",
      "4  28Q680  Queens Gateway to Health Sciences Secondary Sc...     Queens   \n",
      "\n",
      "  building_code    phone_number    fax_number grade_span_min  grade_span_max  \\\n",
      "0          K440    718-230-6250  718-230-6262              9              12   \n",
      "1          X400    718-842-0687  718-589-9849              9              12   \n",
      "2          X240    718-294-8111  718-294-8109              6              12   \n",
      "3          M520  718-935-3477             NaN              9              10   \n",
      "4          Q695    718-969-3155  718-969-3552              6              12   \n",
      "\n",
      "  expgrade_span_min  expgrade_span_max  \\\n",
      "0               NaN                NaN   \n",
      "1               NaN                NaN   \n",
      "2               NaN                NaN   \n",
      "3                 9               14.0   \n",
      "4               NaN                NaN   \n",
      "\n",
      "                         ...                          \\\n",
      "0                        ...                           \n",
      "1                        ...                           \n",
      "2                        ...                           \n",
      "3                        ...                           \n",
      "4                        ...                           \n",
      "\n",
      "                                          priority02  \\\n",
      "0                    Then to New York City residents   \n",
      "1  Then to New York City residents who attend an ...   \n",
      "2  Then to Bronx students or residents who attend...   \n",
      "3  Then to New York City residents who attend an ...   \n",
      "4  Then to Districts 28 and 29 students or residents   \n",
      "\n",
      "                                          priority03  \\\n",
      "0                                                NaN   \n",
      "1                Then to Bronx students or residents   \n",
      "2  Then to New York City residents who attend an ...   \n",
      "3          Then to Manhattan students or residents     \n",
      "4               Then to Queens students or residents   \n",
      "\n",
      "                            priority04                       priority05  \\\n",
      "0                                  NaN                              NaN   \n",
      "1      Then to New York City residents                              NaN   \n",
      "2  Then to Bronx students or residents  Then to New York City residents   \n",
      "3      Then to New York City residents                              NaN   \n",
      "4      Then to New York City residents                              NaN   \n",
      "\n",
      "  priority06  priority07 priority08  priority09 priority10  \\\n",
      "0        NaN         NaN        NaN         NaN        NaN   \n",
      "1        NaN         NaN        NaN         NaN        NaN   \n",
      "2        NaN         NaN        NaN         NaN        NaN   \n",
      "3        NaN         NaN        NaN         NaN        NaN   \n",
      "4        NaN         NaN        NaN         NaN        NaN   \n",
      "\n",
      "                                          Location 1  \n",
      "0  883 Classon Avenue\\nBrooklyn, NY 11225\\n(40.67...  \n",
      "1  1110 Boston Road\\nBronx, NY 10456\\n(40.8276026...  \n",
      "2  1501 Jerome Avenue\\nBronx, NY 10452\\n(40.84241...  \n",
      "3  411 Pearl Street\\nNew York, NY 10038\\n(40.7106...  \n",
      "4  160-20 Goethals Avenue\\nJamaica, NY 11432\\n(40...  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "      DBN                             SchoolName AP Test Takers   \\\n",
      "0  01M448           UNIVERSITY NEIGHBORHOOD H.S.              39   \n",
      "1  01M450                 EAST SIDE COMMUNITY HS              19   \n",
      "2  01M515                    LOWER EASTSIDE PREP              24   \n",
      "3  01M539         NEW EXPLORATIONS SCI,TECH,MATH             255   \n",
      "4  02M296  High School of Hospitality Management               s   \n",
      "\n",
      "  Total Exams Taken Number of Exams with scores 3 4 or 5  \n",
      "0                49                                   10  \n",
      "1                21                                    s  \n",
      "2                26                                   24  \n",
      "3               377                                  191  \n",
      "4                 s                                    s  \n",
      "   CSD BOROUGH SCHOOL CODE                SCHOOL NAME GRADE  PROGRAM TYPE  \\\n",
      "0    1       M        M015  P.S. 015 Roberto Clemente     0K       GEN ED   \n",
      "1    1       M        M015  P.S. 015 Roberto Clemente     0K          CTT   \n",
      "2    1       M        M015  P.S. 015 Roberto Clemente     01       GEN ED   \n",
      "3    1       M        M015  P.S. 015 Roberto Clemente     01          CTT   \n",
      "4    1       M        M015  P.S. 015 Roberto Clemente     02       GEN ED   \n",
      "\n",
      "  CORE SUBJECT (MS CORE and 9-12 ONLY) CORE COURSE (MS CORE and 9-12 ONLY)  \\\n",
      "0                                    -                                   -   \n",
      "1                                    -                                   -   \n",
      "2                                    -                                   -   \n",
      "3                                    -                                   -   \n",
      "4                                    -                                   -   \n",
      "\n",
      "  SERVICE CATEGORY(K-9* ONLY)  NUMBER OF STUDENTS / SEATS FILLED  \\\n",
      "0                           -                               19.0   \n",
      "1                           -                               21.0   \n",
      "2                           -                               17.0   \n",
      "3                           -                               17.0   \n",
      "4                           -                               15.0   \n",
      "\n",
      "   NUMBER OF SECTIONS  AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  \\\n",
      "0                 1.0                19.0                    19.0   \n",
      "1                 1.0                21.0                    21.0   \n",
      "2                 1.0                17.0                    17.0   \n",
      "3                 1.0                17.0                    17.0   \n",
      "4                 1.0                15.0                    15.0   \n",
      "\n",
      "   SIZE OF LARGEST CLASS DATA SOURCE  SCHOOLWIDE PUPIL-TEACHER RATIO  \n",
      "0                   19.0         ATS                             NaN  \n",
      "1                   21.0         ATS                             NaN  \n",
      "2                   17.0         ATS                             NaN  \n",
      "3                   17.0         ATS                             NaN  \n",
      "4                   15.0         ATS                             NaN  \n"
     ]
    }
   ],
   "source": [
    "for key,value in data.items():\n",
    "    print( value.head( 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7: Reading in the Survey Data\n",
    "\n",
    "In the last step, we saw a group of dataframes that looked like this:\n",
    "\n",
    "CSD BOROUGH SCHOOL CODE                SCHOOL NAME GRADE  PROGRAM TYPE  \\\n",
    "\n",
    "0    1       M        M015  P.S. 015 Roberto Clemente     0K       GEN ED\n",
    "\n",
    "1    1       M        M015  P.S. 015 Roberto Clemente     0K          CTT\n",
    "\n",
    "2    1       M        M015  P.S. 015 Roberto Clemente     01       GEN ED\n",
    "\n",
    "3    1       M        M015  P.S. 015 Roberto Clemente     01          CTT\n",
    "\n",
    "4    1       M        M015  P.S. 015 Roberto Clemente     02       GEN ED\n",
    "\n",
    "We can make some observations based on the first few rows of each one.\n",
    "\n",
    "    Each data set appears to either have a DBN column, or the information we need to create one. That means we can use a DBN column to combine the data sets. First we'll pinpoint matching rows from different data sets by looking for identical DBNs, then group all of their columns together in a single data set.\n",
    "    Some fields look interesting for mapping -- particularly Location 1, which contains coordinates inside a larger string.\n",
    "    Some of the data sets appear to contain multiple rows for each school (because the rows have duplicate DBN values). That means we’ll have to do some preprocessing to ensure that each DBN is unique within each data set. If we don't do this, we'll run into problems when we combine the data sets, because we might be merging two rows in one data set with one row in another data set.\n",
    "\n",
    "Before we proceed with the merge, we should make sure we have all of the data we want to unify. We mentioned the survey data earlier (survey_all.txt and survey_d75.txt), but we didn't read those files in because they're in a slightly more complex format.\n",
    "\n",
    "Each survey text file looks like this:\n",
    "\n",
    "    dbn bn  schoolname  d75 studentssurveyed    highschool  schooltype  rr_s\n",
    "\n",
    "    \"01M015\"    \"M015\"  \"P.S. 015 Roberto Clemente\" 0   \"No\"    0   \"Elementary School\"     88\n",
    "\n",
    "The files are tab delimited and encoded with Windows-1252 encoding. An encoding defines how a computer stores the contents of a file in binary. The most common encodings are UTF-8 and ASCII. Windows-1252 is rarely used, and can cause errors if we read such a file in without specifying the encoding. If you'd like to read more about encodings, [here's](http://kunststube.net/encoding/)  a good primer.\n",
    "\n",
    "We'll need to specify the encoding and delimiter to the pandas pandas.read_csv() function to ensure it reads the surveys in properly.\n",
    "\n",
    "After we read in the survey data, we'll want to combine it into a single dataframe. We can do this by calling the pandas.concat() function:\n",
    "\n",
    "    z = pd.concat([x,y], axis=0)\n",
    "\n",
    "The code above will combine dataframes x and y by essentially appending y to the end of x. The combined dataframe z will have the number of rows in x plus the number of rows in y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8: Reading in the Survey Data\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Read in survey_all.txt.\n",
    "        Use the pandas.read_csv() function to read survey_all.txt into the variable all_survey. Recall that this file is located in the schools folder.\n",
    "            Specify the keyword argument delimiter=\"\\t\".\n",
    "            Specify the keyword argument encoding=\"windows-1252\".\n",
    "    Read in survey_d75.txt.\n",
    "        Use the pandas.read_csv() function to read schools/survey_d75.txt into the variable d75_survey. Recall that this file is located in the schools folder.\n",
    "            Specify the keyword argument delimiter=\"\\t\".\n",
    "            Specify the keyword argument encoding=\"windows-1252\".\n",
    "    Combine d75_survey and all_survey into a single dataframe.\n",
    "        Use the pandas concat() function with the keyword argument axis=0 to combine d75_survey and all_survey into the dataframe survey.\n",
    "        Pass in all_survey first, then d75_survey when calling the pandas.concat() function.\n",
    "    Display the first five rows of survey using the pandas.DataFrame.head() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_p</th>\n",
       "      <th>N_s</th>\n",
       "      <th>N_t</th>\n",
       "      <th>aca_p_11</th>\n",
       "      <th>aca_s_11</th>\n",
       "      <th>aca_t_11</th>\n",
       "      <th>aca_tot_11</th>\n",
       "      <th>bn</th>\n",
       "      <th>com_p_11</th>\n",
       "      <th>com_s_11</th>\n",
       "      <th>...</th>\n",
       "      <th>t_q8c_1</th>\n",
       "      <th>t_q8c_2</th>\n",
       "      <th>t_q8c_3</th>\n",
       "      <th>t_q8c_4</th>\n",
       "      <th>t_q9</th>\n",
       "      <th>t_q9_1</th>\n",
       "      <th>t_q9_2</th>\n",
       "      <th>t_q9_3</th>\n",
       "      <th>t_q9_4</th>\n",
       "      <th>t_q9_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>M015</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>M019</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>M020</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>M034</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>M063</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     N_p    N_s   N_t  aca_p_11  aca_s_11  aca_t_11  aca_tot_11    bn  \\\n",
       "0   90.0    NaN  22.0       7.8       NaN       7.9         7.9  M015   \n",
       "1  161.0    NaN  34.0       7.8       NaN       9.1         8.4  M019   \n",
       "2  367.0    NaN  42.0       8.6       NaN       7.5         8.0  M020   \n",
       "3  151.0  145.0  29.0       8.5       7.4       7.8         7.9  M034   \n",
       "4   90.0    NaN  23.0       7.9       NaN       8.1         8.0  M063   \n",
       "\n",
       "   com_p_11  com_s_11   ...    t_q8c_1  t_q8c_2  t_q8c_3 t_q8c_4  t_q9  \\\n",
       "0       7.6       NaN   ...       29.0     67.0      5.0     0.0   NaN   \n",
       "1       7.6       NaN   ...       74.0     21.0      6.0     0.0   NaN   \n",
       "2       8.3       NaN   ...       33.0     35.0     20.0    13.0   NaN   \n",
       "3       8.2       5.9   ...       21.0     45.0     28.0     7.0   NaN   \n",
       "4       7.9       NaN   ...       59.0     36.0      5.0     0.0   NaN   \n",
       "\n",
       "   t_q9_1  t_q9_2  t_q9_3  t_q9_4  t_q9_5  \n",
       "0     5.0    14.0    52.0    24.0     5.0  \n",
       "1     3.0     6.0     3.0    78.0     9.0  \n",
       "2     3.0     5.0    16.0    70.0     5.0  \n",
       "3     0.0    18.0    32.0    39.0    11.0  \n",
       "4    10.0     5.0    10.0    60.0    15.0  \n",
       "\n",
       "[5 rows x 2773 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_survey = pd.read_csv( \"../data/survey_all.txt\", delimiter=\"\\t\", encoding=\"windows-1252\" )\n",
    "d75_survey = pd.read_csv( \"../data/survey_d75.txt\", delimiter=\"\\t\", encoding=\"windows-1252\" )\n",
    "\n",
    "survey = pd.concat( [ all_survey, d75_survey ] , axis=0 )\n",
    "survey.head( 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9: Cleaning Up the Surveys\n",
    "\n",
    "In the last step, you should have seen output that looked like this:\n",
    "\n",
    "N_p  N_s  N_t  aca_p_11  aca_s_11  aca_t_11  aca_tot_11    bn  com_p_11  \\\n",
    "\n",
    "0   90  NaN   22       7.8       NaN       7.9         7.9  M015       7.6   \n",
    "\n",
    "1  161  NaN   34       7.8       NaN       9.1         8.4  M019       7.6\n",
    "\n",
    "There are two immediate facts that we can see in the data:\n",
    "\n",
    "    There are over 2000 columns, nearly all of which we don't need. We'll have to filter the data to remove the unnecessary ones. Working with fewer columns will make it easier to print the dataframe out and find correlations within it.\n",
    "    The survey data has a dbn column that we'll want to convert to uppercase (DBN). The conversion will make the column name consistent with the other data sets.\n",
    "\n",
    "First, we'll need filter the columns to remove the ones we don't need. Luckily, there's a data dictionary at the original data download location. The dictionary tells us what each column represents. Based on our knowledge of the problem and the analysis we're trying to do, we can use the data dictionary to determine which columns to use.\n",
    "\n",
    "Here's a preview of the data dictionary:\n",
    "\n",
    "<img src=\"xj5ud4r.png\">\n",
    "\n",
    "Based on the dictionary, it looks like these are the relevant columns:\n",
    "\n",
    "    [\"dbn\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\", \"com_p_11\", \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\", \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n",
    "\n",
    "These columns will give us aggregate survey data about how parents, teachers, and students feel about school safety, academic performance, and more. It will also give us the DBN, which allows us to uniquely identify the school.\n",
    "\n",
    "Before we filter columns out, we'll want to copy the data from the dbn column into a new column called DBN. We can copy columns like this:\n",
    "\n",
    "    survey[\"new_column\"] = survey[\"old_column\"]\n",
    "\n",
    "## Instructions\n",
    "\n",
    "    Copy the data from the dbn column of survey into a new column in survey called DBN.\n",
    "    Filter survey so it only contains the columns we listed above. You can do this using pandas.DataFrame.loc[].\n",
    "        Remember that we renamed dbn to DBN; be sure to change the list of columns we want to keep accordingly.\n",
    "    Assign the dataframe survey to the key survey in the dictionary data.\n",
    "    When you're finished, the value in data[\"survey\"] should be a dataframe with 23 columns and 1702 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survey[\"DBN\"] = survey[\"dbn\"]\n",
    "survey_cols = [\"dbn\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\", \"com_p_11\", \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\", \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n",
    "[\"dbn\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\", \"com_p_11\", \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\", \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\", \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]\n",
    "\n",
    "data['survey'] = survey.loc[:,survery_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10: Inserting DBN Fields\n",
    "\n",
    "When we explored all of the data sets, we noticed that some of them, like class_size and hs_directory, don't have a DBN column. hs_directory does have a dbn column, though, so we can just rename it.\n",
    "\n",
    "However, class_size doesn't appear to have the column at all. Here are the first few rows of the data set:\n",
    "\n",
    "CSD BOROUGH SCHOOL CODE                SCHOOL NAME GRADE  PROGRAM TYPE  \\\n",
    "\n",
    "0    1       M        M015  P.S. 015 Roberto Clemente     0K       GEN ED\n",
    "\n",
    "1    1       M        M015  P.S. 015 Roberto Clemente     0K          CTT\n",
    "\n",
    "2    1       M        M015  P.S. 015 Roberto Clemente     01       GEN ED\n",
    "\n",
    "3    1       M        M015  P.S. 015 Roberto Clemente     01          CTT\n",
    "\n",
    "4    1       M        M015  P.S. 015 Roberto Clemente     02       GEN ED\n",
    "\n",
    "Here are the first few rows of the sat_results data, which does have a DBN column:\n",
    "\n",
    "DBN                                    SCHOOL NAME  \\\n",
    "\n",
    "0  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL STUDIES\n",
    "\n",
    "1  01M448            UNIVERSITY NEIGHBORHOOD HIGH SCHOOL\n",
    "\n",
    "2  01M450                     EAST SIDE COMMUNITY SCHOOL\n",
    "\n",
    "3  01M458                      FORSYTH SATELLITE ACADEMY\n",
    "\n",
    "4  01M509                        MARTA VALLE HIGH SCHOOL\n",
    "\n",
    "From looking at these rows, we can tell that the DBN in the sat_results data is just a combination of the CSD and SCHOOL CODE columns in the class_size data. The main difference is that the DBN is padded, so that the CSD portion of it always consists of two digits. That means we'll need to add a leading 0 to the CSD if the CSD is less than two digits long. Here's a diagram illustrating what we need to do:\n",
    "\n",
    "    CSD Padded CSD\n",
    "    1       01\n",
    "    19      19\n",
    "    2       02\n",
    "    99      99\n",
    "\n",
    "As you can see, whenever the CSD is less than two digits long, we need to add a leading 0. We can accomplish this using the pandas pandas.DataFrame.apply() method, along with a custom function that:\n",
    "\n",
    "    Takes in a number.\n",
    "    Converts the number to a string using the str() function.\n",
    "    Check the length of the string using the len() function.\n",
    "        If the string is two digits long, returns the string.\n",
    "        If the string is one digit long, adds a 0 to the front of the string, then returns it.\n",
    "            You can use the string method zfill() to do this.\n",
    "\n",
    "Once we've padded the CSD, we can use the addition operator (+) to combine the values in the CSD and SCHOOL CODE columns. Here's an example of how we would do this:\n",
    "\n",
    "    dataframe[\"new_column\"] = dataframe[\"column_one\"] + dataframe[\"column_two\"]\n",
    "\n",
    "And here's a diagram illustrating the basic concept:\n",
    "\n",
    "PaddedCSD + SchoolCode = DBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11: Inserting DBN Fields\n",
    "\n",
    "## Instructions\n",
    "\n",
    "\n",
    "    Copy the dbn column in hs_directory into a new column called DBN.\n",
    "    Create a new column called padded_csd in the class_size data set.\n",
    "        Use the pandas.DataFrame.apply() method along with a custom function to generate this column.\n",
    "            Make sure to apply the function along the data[\"class_size\"][\"CSD\"] column.\n",
    "    Use the addition operator (+) along with the padded_csd and SCHOOL CODE columns of class_size, then assign the result to the DBN column of class_size.\n",
    "    Display the first few rows of class_size to double check the DBN column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'type' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-55291b7d5093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hs_directory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DBN'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hs_directory'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dbn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"padded_csd\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CSD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpadcsd\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DBN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"padded_csd\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SCHOOL CODE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayush/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2294\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:66124)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-55291b7d5093>\u001b[0m in \u001b[0;36mpadcsd\u001b[0;34m(number)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpadcsd\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnumber_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mnumber_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumber_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'type' has no len()"
     ]
    }
   ],
   "source": [
    "def padcsd( number ):\n",
    "    number_str = str( number )\n",
    "    if len( str ) > 1:\n",
    "        number_str = '0' + number_str\n",
    "    return number\n",
    "    \n",
    "\n",
    "data['hs_directory']['DBN'] = data['hs_directory']['dbn']\n",
    "\n",
    "data['class_size'][\"padded_csd\"] = data['class_size']['CSD'].apply( padcsd )\n",
    "data['class_size'][\"DBN\"] = data['class_size'][\"padded_csd\"] + data['class_size'][\"SCHOOL CODE\"]\n",
    "data['class_size'].head( 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
